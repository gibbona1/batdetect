{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dce7c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddbc7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_fns import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e69fedb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set: norfolk\n"
     ]
    }
   ],
   "source": [
    "test_set      = 'norfolk'  # can be one of: bulgaria, uk, norfolk\n",
    "data_set      = 'bat_train/data/train_test_split/test_set_' + test_set + '.npz'\n",
    "raw_audio_dir = 'bat_train/data/wav/'\n",
    "base_line_dir = 'bat_train/data/baselines/'\n",
    "result_dir    = 'bat_train/results/'\n",
    "model_dir     = 'bat_train/data/models/'\n",
    "if not os.path.isdir(result_dir):\n",
    "    os.mkdir(result_dir)\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "print('test set:', test_set)\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f1c1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test_pos are in units of seconds\n",
    "loaded_data_tr  = np.load(data_set, allow_pickle = True, encoding = 'latin1')\n",
    "train_pos       = loaded_data_tr['train_pos']\n",
    "train_files     = loaded_data_tr['train_files']\n",
    "train_durations = loaded_data_tr['train_durations']\n",
    "test_pos        = loaded_data_tr['test_pos']\n",
    "test_files      = loaded_data_tr['test_files']\n",
    "test_durations  = loaded_data_tr['test_durations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc74d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files_decode = [s.decode() for s in train_files]\n",
    "test_files_decode  = [s.decode() for s in test_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2a9b603",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions, class_labels = generate_training_positions(train_files_decode, train_pos, train_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2476f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths_decode = [raw_audio_dir + fn for fn in train_files_decode]\n",
    "test_paths_decode  = [raw_audio_dir + fn for fn in test_files_decode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2dc7741",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths_decode_full = [s+'.wav' for s in train_paths_decode]\n",
    "test_paths_decode_full  = [s+'.wav' for s in test_paths_decode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1cf0da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_waveform_and_label(file_path):\n",
    "    label        = get_label(file_path)\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform     = decode_audio(audio_binary)\n",
    "    return waveform, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9da4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    #Second last part is the folder the file is contained in, i.e. the label\n",
    "    return parts[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a37d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_audio(audio_binary):\n",
    "    audio, _ = tf.audio.decode_wav(audio_binary) # returns the WAV-encoded audio as a tensor and the sample rate\n",
    "    #if there is both left and right audio, only keep the left source to avoid dimension problems\n",
    "    return audio[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf9b3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_post(spec):\n",
    "    spec = spec[1:, :]\n",
    "    spec = np.flipud(spec)\n",
    "    # only keep the relevant bands - could do this outside\n",
    "    if crop_spec:\n",
    "        spec = spec[-max_freq:-min_freq, :]\n",
    "    \n",
    "        # add some zeros if too small\n",
    "        req_height = max_freq-min_freq\n",
    "        if spec.shape[0] < req_height:\n",
    "            zero_pad = np.zeros((req_height-spec.shape[0], spec.shape[1]))\n",
    "            spec     = np.vstack((zero_pad, spec))\n",
    "\n",
    "    # perform log scaling - here the same as matplotlib\n",
    "    log_scaling = 2.0 * (1.0 / sampling_rate) * (1.0/(np.abs(np.hanning(int(fft_win_length*sampling_rate)))**2).sum())\n",
    "    spec        = np.log(1.0 + log_scaling*spec)\n",
    "    return(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95c69694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "    #cutoff spectrogram size to either splice or pad\n",
    "    nfft     = int(fft_win_length*sampling_rate)\n",
    "    noverlap = int(fft_overlap*nfft)\n",
    "\n",
    "    # window data\n",
    "    step    = nfft - noverlap\n",
    "    #print(step)\n",
    "    shape   = (nfft, (waveform.shape[-1]-noverlap)//step)\n",
    "    strides = (waveform.strides[0], step*waveform.strides[0])\n",
    "    x_wins  = np.lib.stride_tricks.as_strided(waveform, shape=shape, strides=strides)\n",
    "    x_wins_han = np.hanning(x_wins.shape[0])[..., np.newaxis] * x_wins\n",
    "    \n",
    "    complex_spec = tf.signal.rfft(x_wins_han.T).numpy().T\n",
    "    spec = tf.math.real(tf.math.conj(complex_spec) * complex_spec)\n",
    "    spec = spec_post(spec)\n",
    "    spec = process_spectrogram(spec, denoise_spec=denoise, mean_log_mag=mean_log_mag, smooth_spec=smooth_spec)\n",
    "    \n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57e6fde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines appropriate number of processes that are free for working.\n",
    "AUTOTUNE    = tf.data.experimental.AUTOTUNE\n",
    "#Creates tensorflow dataset with (waveform, label) pairs\n",
    "files_ds    = tf.data.Dataset.from_tensor_slices(train_paths_decode_full)\n",
    "waveform_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "568cc159",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "slice index -1 of dimension 0 out of bounds.\n\t [[{{node strided_slice}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-600f5f225092>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mwf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlab\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwaveform_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    759\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[0;32m    745\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   2725\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2726\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2727\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2728\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2729\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6940\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6941\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6942\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: slice index -1 of dimension 0 out of bounds.\n\t [[{{node strided_slice}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "for wf,lab in waveform_ds.take(1):\n",
    "    print(lab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
