{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "568cc159",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'write_op'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7c78cad8b277>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mwrite_op\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdata_set_params\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataSetParams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#import sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'write_op'"
     ]
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "#import pickle\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import write_op as wo\n",
    "from data_set_params import DataSetParams\n",
    "#import sys\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras import models, layers, regularizers\n",
    "from helper_fns import compute_features, nms_1d\n",
    "#import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.filters import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f61247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio(file_name, do_time_expansion, chunk_size, win_size):\n",
    "\n",
    "    # try to read in audio file\n",
    "    try:\n",
    "        samp_rate_orig, audio = wavfile.read(file_name)\n",
    "    except:\n",
    "        print('  Error reading file')\n",
    "        return True, None, None, None, None\n",
    "\n",
    "    # convert to mono if stereo\n",
    "    if len(audio.shape) == 2:\n",
    "        print('  Warning: stereo file. Just taking right channel.')\n",
    "        audio = audio[:, 1]\n",
    "    file_dur = audio.shape[0] / float(samp_rate_orig)\n",
    "    print('  dur', round(file_dur,3), '(secs) , fs', samp_rate_orig)\n",
    "\n",
    "    # original model is trained on time expanded data\n",
    "    samp_rate = samp_rate_orig\n",
    "    if do_time_expansion:\n",
    "        samp_rate = int(samp_rate_orig/10.0)\n",
    "        file_dur *= 10\n",
    "\n",
    "    # pad with zeros so we can go right to the end\n",
    "    multiplier = np.ceil(file_dur/float(chunk_size-win_size))\n",
    "    diff       = multiplier*(chunk_size-win_size) - file_dur + win_size\n",
    "    audio_pad  = np.hstack((audio, np.zeros(int(diff*samp_rate))))\n",
    "\n",
    "    return False, audio_pad, file_dur, samp_rate, samp_rate_orig\n",
    "\n",
    "\n",
    "def run_detector(det, audio, file_dur, samp_rate, detection_thresh, params):\n",
    "\n",
    "    det_time = []\n",
    "    det_prob = []\n",
    "\n",
    "    # files can be long so we split each up into separate (overlapping) chunks\n",
    "    st_positions = np.arange(0, file_dur, params.chunk_size-params.window_size)\n",
    "    #print('st_positions',st_positions)\n",
    "    for chunk_id, st_position in enumerate(st_positions):\n",
    "\n",
    "        # take a chunk of the audio\n",
    "        # should already be zero padded at the end so its the correct size\n",
    "        st_pos      = int(st_position*samp_rate)\n",
    "        en_pos      = int(st_pos + params.chunk_size*samp_rate)\n",
    "        audio_chunk = audio[st_pos:en_pos]\n",
    "        \n",
    "        # make predictions\n",
    "        chunk_spec  = compute_features(audio_chunk, samp_rate, params)\n",
    "        chunk_spec  = np.squeeze(chunk_spec)\n",
    "        chunk_spec  = np.expand_dims(chunk_spec,-1)\n",
    "        \n",
    "        det_pred    = det.predict(chunk_spec)\n",
    "        \n",
    "        if params.smooth_op_prediction:\n",
    "            det_pred = gaussian_filter1d(det_pred, params.smooth_op_prediction_sigma, axis=0)\n",
    "        \n",
    "        pos, prob = nms_1d(det_pred[:,0], params.nms_win_size, file_dur)\n",
    "        prob      = prob[:,0]\n",
    "        \n",
    "        # remove predictions near the end (if not last chunk) and ones that are\n",
    "        # below the detection threshold\n",
    "        if chunk_id == (len(st_positions)-1):\n",
    "            inds = (prob >= detection_thresh)\n",
    "        else:\n",
    "            inds = np.logical_and((prob >= detection_thresh), (pos < (params.chunk_size-(params.window_size/2.0))))\n",
    "\n",
    "        # convert detection time back into global time and save valid detections\n",
    "        if pos.shape[0] > 0:\n",
    "            det_time.append(pos[inds] + st_position)\n",
    "            det_prob.append(prob[inds])\n",
    "\n",
    "    if len(det_time) > 0:\n",
    "        det_time = np.hstack(det_time)\n",
    "        det_prob = np.hstack(det_prob)\n",
    "\n",
    "        # undo the effects of times expansion\n",
    "        if do_time_expansion:\n",
    "            det_time /= 10.0\n",
    "\n",
    "    return det_time, det_prob\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    This code takes a directory of audio files and runs a CNN based bat call\n",
    "    detector. It returns the time in file of the detection and the probability\n",
    "    that the detection is a bat call.\n",
    "    \"\"\"\n",
    "\n",
    "    # params\n",
    "    detection_thresh  = 0.80  # make this smaller if you want more calls detected\n",
    "    do_time_expansion = True  # set to True if audio is not already time expanded\n",
    "    save_res          = True  # save detections\n",
    "\n",
    "    params = DataSetParams()\n",
    "\n",
    "    # load data -\n",
    "    data_dir   = 'data/labelled_data/'+params.test_set+'/test/' # path of the data that we run the model on\n",
    "    op_ann_dir = 'results/detections/'      # where we will store the outputs\n",
    "    op_file_name_total = op_ann_dir + 'op_file.csv'\n",
    "    if not os.path.isdir(op_ann_dir):\n",
    "        os.makedirs(op_ann_dir)\n",
    "\n",
    "    # load gpu lasagne model\n",
    "    model_dir  = 'results/bulgaria_big_cnn'\n",
    "\n",
    "    det = tf.keras.models.load_model(model_dir)\n",
    "\n",
    "    params.chunk_size = 4.0\n",
    "\n",
    "    # read audio files\n",
    "    audio_files = glob.glob(data_dir + '*.wav')[:5]\n",
    "    #print(audio_files)\n",
    "    # loop through audio files\n",
    "    results = []\n",
    "    for file_cnt, file_name in enumerate(audio_files):\n",
    "\n",
    "        file_name_root = file_name[len(data_dir):]\n",
    "        print('\\n', file_cnt+1, 'of', len(audio_files), '\\t', file_name_root)\n",
    "\n",
    "        # read audio file - skip file if cannot read\n",
    "        read_fail, audio, file_dur, samp_rate, samp_rate_orig = read_audio(file_name,\n",
    "                                do_time_expansion, params.chunk_size, params.window_size)\n",
    "        if read_fail:\n",
    "            continue\n",
    "\n",
    "        # run detector\n",
    "        tic = time.time()\n",
    "        det_time, det_prob = run_detector(det, audio, file_dur, samp_rate, detection_thresh, params)\n",
    "        toc = time.time()\n",
    "\n",
    "        print('  detection time', round(toc-tic, 3), '(secs)')\n",
    "        num_calls = len(det_time)\n",
    "        print('  ' + str(num_calls) + ' calls found')\n",
    "\n",
    "        # save results\n",
    "        if save_res:\n",
    "            # return detector results\n",
    "            pred_classes = np.zeros((len(det_time), 1), dtype=np.int)\n",
    "            pred_prob    = np.asarray(det_prob)[..., np.newaxis]\n",
    "\n",
    "            # save to AudioTagger format\n",
    "            op_file_name = op_ann_dir + file_name_root[:-4] + '-sceneRect.csv'\n",
    "            wo.create_audio_tagger_op(file_name_root, op_file_name, det_time,\n",
    "                                      det_prob, pred_classes[:,0], pred_prob[:,0],\n",
    "                                      samp_rate_orig, np.asarray(['bat']))\n",
    "\n",
    "            # save as dictionary\n",
    "            if num_calls > 0:\n",
    "                res = {'filename':file_name_root, 'time':det_time,\n",
    "                       'prob':det_prob, 'pred_classes':pred_classes,\n",
    "                       'pred_prob':pred_prob}\n",
    "                results.append(res)\n",
    "\n",
    "    # save to large csv\n",
    "    if save_res and (len(results) > 0):\n",
    "        print('\\nsaving results to', op_file_name_total)\n",
    "        wo.save_to_txt(op_file_name_total, results, np.asarray(['bat']))\n",
    "    else:\n",
    "        print('no detections to save')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
